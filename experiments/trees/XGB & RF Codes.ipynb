{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6d625dbe-ae2b-42cb-9d9a-a5a2324bbfde",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Datensätze laden\n",
    "\n",
    "import pickle\n",
    "\n",
    "file_path_X_train = \"splits/train/X_pandas.pck\"\n",
    "file_path_y_train = \"splits/train/y_pandas.pck\"\n",
    "file_path_X_test = \"splits/test/X_pandas.pck\"\n",
    "file_path_y_test = \"splits/test/y_pandas.pck\"\n",
    "file_path_X_val = \"splits/val/X_pandas.pck\"\n",
    "file_path_y_val = \"splits/val/y_pandas.pck\"\n",
    "\n",
    "# Pickle-Dateien einzeln laden\n",
    "with open(file_path_X_train, 'rb') as file:\n",
    "    X_train = pickle.load(file)\n",
    "\n",
    "with open(file_path_y_train, 'rb') as file:\n",
    "    y_train = pickle.load(file)\n",
    "\n",
    "with open(file_path_X_test, 'rb') as file:\n",
    "    X_test = pickle.load(file)\n",
    "\n",
    "with open(file_path_y_test, 'rb') as file:\n",
    "    y_test = pickle.load(file)\n",
    "\n",
    "with open(file_path_X_val, 'rb') as file:\n",
    "    X_val = pickle.load(file)\n",
    "\n",
    "with open(file_path_y_val, 'rb') as file:\n",
    "    y_val = pickle.load(file)\n",
    "\n",
    "# print(os.listdir('/content/drive/MyDrive/splits/test'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "beb6e3b1-0dc3-4783-8c83-d5f455044889",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Code um verschiedene Modellkonfigurationen/ Hyperparameter für XGBoost Modelle zu testen. Hieraus hat sich ein bestes Modell ergeben, das im nachfolgenden Code separat nochmal trainiert wurde.\n",
    "import optuna\n",
    "import xgboost as xgb\n",
    "from scipy.sparse import csr_matrix\n",
    "from sklearn.metrics import accuracy_score, f1_score, recall_score, precision_score\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "X_train_csr = csr_matrix(X_train)\n",
    "X_test_csr = csr_matrix(X_test)  \n",
    "\n",
    "def objective(trial):\n",
    "    params = {\n",
    "        'max_depth': trial.suggest_int('max_depth', 5, 12),\n",
    "        'learning_rate': trial.suggest_float('learning_rate', 0.05, 0.3),\n",
    "        'n_estimators': trial.suggest_int('n_estimators', 50, 100),\n",
    "        'subsample': trial.suggest_float('subsample', 0.8, 1.0),\n",
    "        'colsample_bytree': trial.suggest_float('colsample_bytree', 0.5, 1.0),\n",
    "        'gamma': trial.suggest_float('gamma', 0, 1.0),\n",
    "        'reg_alpha': trial.suggest_float('reg_alpha', 0, 1.0),\n",
    "        'reg_lambda': trial.suggest_float('reg_lambda', 0, 1.0),\n",
    "        'min_child_weight': trial.suggest_int('min_child_weight', 1, 10),\n",
    "    }\n",
    "    \n",
    "    model = xgb.XGBClassifier(**params, random_state=42)\n",
    "    model.fit(X_train_csr, y_train)\n",
    "    \n",
    "    test_preds = model.predict(X_test_csr)\n",
    "   \n",
    "    test_accuracy = accuracy_score(y_test, test_preds)\n",
    "    test_f1 = f1_score(y_test, test_preds, average=\"weighted\")\n",
    "    test_recall = recall_score(y_test, test_preds, average=\"weighted\")\n",
    "    test_precision = precision_score(y_test, test_preds, average=\"weighted\")\n",
    "    \n",
    "    print(f\"Durchlauf {trial.number}: Acc = {test_accuracy:.4f}, F1 = {test_f1:.4f}, Rec = {test_recall:.4f}, Pre = {test_precision:.4f}\")\n",
    "    return test_accuracy\n",
    "\n",
    "study = optuna.create_study(direction=\"maximize\")\n",
    "study.optimize(objective, n_trials=50)\n",
    "\n",
    "print(\"Beste Parameter: \", study.best_params)\n",
    "print(\"Beste Score (Test Accuracy): \", study.best_value)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "80adcbbd-046e-4978-99fa-aa75e37bb856",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Training der besten Konfig. mit Angabe der Params und Speicherung\n",
    "import xgboost as xgb\n",
    "from sklearn.metrics import accuracy_score\n",
    "import sklearn as skl\n",
    "from scipy.sparse import csr_matrix\n",
    "\n",
    "X_train_csr = csr_matrix(X_train)\n",
    "X_test_csr = csr_matrix(X_test)\n",
    "\n",
    "param = {\n",
    "    'max_depth': 7,\n",
    "    'learning_rate': 0.08,\n",
    "    'n_estimators': 300,\n",
    "    'subsample': 0.8,\n",
    "    'colsample_bytree': 0.7,\n",
    "    'gamma': 1.0,\n",
    "    'reg_alpha': 5,\n",
    "    'reg_lambda': 10,\n",
    "    'min_child_weight': 8,\n",
    "}\n",
    "\n",
    "model = xgb.XGBClassifier(\n",
    "    **param,\n",
    "    random_state=42,\n",
    "    n_jobs=-1\n",
    ")\n",
    "\n",
    "model.fit(X_train_csr, y_train)\n",
    "\n",
    "model.save_model(\"2.model\")\n",
    "\n",
    "y_pred_test = model.predict(X_test_csr)\n",
    "y_pred_train = model.predict(X_train_csr)\n",
    "\n",
    "accuracy = accuracy_score(y_test, y_pred_test)\n",
    "print(f\"Test Accuracy: {accuracy}\")\n",
    "\n",
    "accuracy = accuracy_score(y_train, y_pred_train)\n",
    "print(f\"Train Accuracy: {accuracy}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "135c8c30-d668-4a6d-a3ed-20958b3411ce",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Bestes XGBoost Modell (2.model) Evaluation (Metriken)\n",
    "from scipy.sparse import csr_matrix\n",
    "import xgboost as xgb\n",
    "from sklearn.metrics import accuracy_score, precision_score, recall_score, f1_score\n",
    "import pandas as pd\n",
    "\n",
    "def metrics_test(models):\n",
    "    results = []\n",
    "\n",
    "    y_test_csr = csr_matrix(y_test)\n",
    "    x_test_csr = csr_matrix(X_test)\n",
    "\n",
    "    y_train_csr = csr_matrix(y_train)\n",
    "    x_train_csr = csr_matrix(X_train)\n",
    "\n",
    "    model = xgb.XGBClassifier()\n",
    "\n",
    "    for m in models:\n",
    "        model.load_model(m)\n",
    "\n",
    "        y_pred_test = model.predict(x_test_csr)\n",
    "        accuracy_test = accuracy_score(y_test_csr, y_pred_test)\n",
    "        precision_test = precision_score(y_test_csr, y_pred_test, average=\"micro\", zero_division=0)\n",
    "        recall_test = recall_score(y_test_csr, y_pred_test, average=\"micro\")\n",
    "        f1_test = f1_score(y_test_csr, y_pred_test, average=\"micro\")\n",
    "\n",
    "        y_pred_prob_test = model.predict_proba(X_test)\n",
    "        auc_test = roc_auc_score(y_test, y_pred_prob_test, average=\"macro\", multi_class=\"ovr\")\n",
    "\n",
    "        y_pred_train = model.predict(x_train_csr)\n",
    "        accuracy_train = accuracy_score(y_train_csr, y_pred_train)\n",
    "        precision_train = precision_score(y_train_csr, y_pred_train, average=\"micro\", zero_division=0)\n",
    "        recall_train = recall_score(y_train_csr, y_pred_train, average=\"micro\")\n",
    "        f1_train = f1_score(y_train_csr, y_pred_train, average=\"micro\")\n",
    "\n",
    "        y_pred_prob_train = model.predict_proba(X_train)\n",
    "        auc_train = roc_auc_score(y_train, y_pred_prob_train, average=\"macro\", multi_class=\"ovr\")\n",
    "\n",
    "        results.append({\n",
    "            \"Model\": m,\n",
    "            \"Accuracy (Test)\": accuracy_test,\n",
    "            \"Precision (Test)\": precision_test,\n",
    "            \"Recall (Test)\": recall_test,\n",
    "            \"F1 Score (Test)\": f1_test,\n",
    "            \"AUC Score (Test)\": auc_test,\n",
    "            \"Accuracy (Train)\": accuracy_train,\n",
    "            \"Precision (Train)\": precision_train,\n",
    "            \"Recall (Train)\": recall_train,\n",
    "            \"F1 Score (Train)\": f1_train,\n",
    "            \"AUC Score (Train)\": auc_train,\n",
    "        })\n",
    "\n",
    "    return pd.DataFrame(results)\n",
    "\n",
    "models = [\"2.model\"]\n",
    "results_df = metrics_test(models)\n",
    "\n",
    "print(results_df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d7ae67c3-9cbe-44f4-9052-ab56b3edf980",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Training und Eval vom besten XGBoost Modell, mit PCA (50, 100 und 200 Features)\n",
    "from sklearn.decomposition import PCA\n",
    "from sklearn.metrics import accuracy_score, precision_score, recall_score, f1_score, roc_auc_score\n",
    "from scipy.sparse import csr_matrix\n",
    "import xgboost as xgb\n",
    "import pandas as pd\n",
    "\n",
    "X_train_csr = csr_matrix(X_train)\n",
    "X_test_csr = csr_matrix(X_test)\n",
    "\n",
    "n_components_list = [200, 100, 50]\n",
    "\n",
    "results = []\n",
    "\n",
    "param = {\n",
    "    'max_depth': 7,\n",
    "    'learning_rate': 0.08,\n",
    "    'n_estimators': 300,\n",
    "    'subsample': 0.8,\n",
    "    'colsample_bytree': 0.7,\n",
    "    'gamma': 1.0,\n",
    "    'reg_alpha': 5,\n",
    "    'reg_lambda': 10,\n",
    "    'min_child_weight': 8,\n",
    "}\n",
    "\n",
    "for n_components in n_components_list:\n",
    "    print(f\"Komponentenanzahl {n_components}\")\n",
    "    \n",
    "    # PCA\n",
    "    pca = PCA(n_components=n_components)\n",
    "    X_train_pca = pca.fit_transform(X_train_csr.toarray())\n",
    "    X_test_pca = pca.transform(X_test_csr.toarray())\n",
    "    print(\"pca done\")\n",
    "\n",
    "    model = xgb.XGBClassifier(**param, random_state=42, n_jobs=-1)\n",
    "    model.fit(X_train_pca, y_train)\n",
    "    print(\"modell fitted\")\n",
    "    \n",
    "    y_pred_test = model.predict(X_test_pca)\n",
    "    y_pred_train = model.predict(X_train_pca)\n",
    "    y_pred_prob_test = model.predict_proba(X_test_pca)\n",
    "    y_pred_prob_train = model.predict_proba(X_train_pca)\n",
    "    print(\"preds done\")\n",
    "    \n",
    "    # Metriken Test\n",
    "    accuracy_test = accuracy_score(y_test, y_pred_test)\n",
    "    precision_test = precision_score(y_test, y_pred_test, average=\"micro\", zero_division=0)\n",
    "    recall_test = recall_score(y_test, y_pred_test, average=\"micro\")\n",
    "    f1_test = f1_score(y_test, y_pred_test, average=\"macro\")\n",
    "    auc_test = roc_auc_score(y_test, y_pred_prob_test, average=\"macro\", multi_class=\"ovr\")\n",
    "    # print(f\"acc test:{accuracy_test}\")\n",
    "    \n",
    "    # Metriken Train\n",
    "    accuracy_train = accuracy_score(y_train, y_pred_train)\n",
    "    precision_train = precision_score(y_train, y_pred_train, average=\"micro\", zero_division=0)\n",
    "    recall_train = recall_score(y_train, y_pred_train, average=\"micro\")\n",
    "    f1_train = f1_score(y_train, y_pred_train, average=\"macro\")\n",
    "    auc_train = roc_auc_score(y_train, y_pred_prob_train, average=\"macro\", multi_class=\"ovr\")\n",
    "    # print(f\"acc test:{accuracy_train}\")\n",
    "\n",
    "    results.append({\n",
    "        'PCA Components': n_components,\n",
    "        'Accuracy (Test)': accuracy_test,\n",
    "        'Precision (Test)': precision_test,\n",
    "        'Recall (Test)': recall_test,\n",
    "        'F1 (Test)': f1_test,\n",
    "        'AUC (Test)': auc_test,\n",
    "        'Accuracy (Train)': accuracy_train,\n",
    "        'Precision (Train)': precision_train,\n",
    "        'Recall (Train)': recall_train,\n",
    "        'F1 (Train)': f1_train,\n",
    "        'AUC (Train)': auc_train,\n",
    "    })\n",
    "\n",
    "results_df = pd.DataFrame(results)\n",
    "\n",
    "print(results_df)\n",
    "\n",
    "results_df.to_csv(\"xgboost_pca_ergebnisse.csv\", index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "809788cf-ac87-411c-93bc-db4d911eab1b",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Code für verschiedene Konfigurationen von Random Forest Modellen mit anschließender Eval für das beste Modell\n",
    "import optuna\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.metrics import accuracy_score, precision_score, recall_score, f1_score\n",
    "from sklearn.model_selection import train_test_split\n",
    "import numpy as np\n",
    "import joblib\n",
    "import os\n",
    "\n",
    "os.makedirs(\"saved_models\", exist_ok=True)\n",
    "\n",
    "def objective(trial):\n",
    "\n",
    "    n_estimators = trial.suggest_int(\"n_estimators\", 50, 100)\n",
    "    max_depth = trial.suggest_categorical(\"max_depth\", [None] + list(range(5, 51)))\n",
    "    criterion = trial.suggest_categorical(\"criterion\", [\"gini\", \"entropy\", \"log_loss\"])\n",
    "    min_samples_split = trial.suggest_int(\"min_samples_split\", 2, 10)\n",
    "    min_samples_leaf = trial.suggest_int(\"min_samples_leaf\", 1, 10)\n",
    "    max_features = trial.suggest_categorical(\"max_features\", [\"sqrt\", \"log2\", None])\n",
    "    bootstrap = trial.suggest_categorical(\"bootstrap\", [True, False])\n",
    "\n",
    "    model = RandomForestClassifier(\n",
    "        n_estimators=n_estimators,\n",
    "        max_depth=max_depth,\n",
    "        criterion=criterion,\n",
    "        min_samples_split=min_samples_split,\n",
    "        min_samples_leaf=min_samples_leaf,\n",
    "        max_features=max_features,\n",
    "        bootstrap=bootstrap,\n",
    "        random_state=42,\n",
    "        n_jobs=-1,\n",
    "        verbose=2\n",
    "    )\n",
    "\n",
    "    model.fit(X_train, y_train)\n",
    "\n",
    "    y_pred = model.predict(X_test)\n",
    "    accuracy = accuracy_score(y_test, y_pred)\n",
    "\n",
    "    model_filename = f\"saved_models/model_trial_{trial.number}.model\"\n",
    "    joblib.dump(model, model_filename)\n",
    "    print(f\"Modell für Durchlauf {trial.number} gespeichert: {model_filename}\")\n",
    "\n",
    "    return accuracy\n",
    "\n",
    "study = optuna.create_study(direction=\"maximize\")\n",
    "study.optimize(objective, n_trials=15)\n",
    "\n",
    "print(\"Beste Hyperparams:\", study.best_params)\n",
    "print(\"Beste Acc:\", study.best_value)\n",
    "\n",
    "best_params = study.best_params\n",
    "best_model = RandomForestClassifier(**best_params, random_state=42, n_jobs=-1, verbose=2)\n",
    "best_model.fit(X_train, y_train) #Best Modell trainieren\n",
    "\n",
    "#Eval Test\n",
    "y_pred_test = best_model.predict(X_test)\n",
    "accuracy_test = accuracy_score(y_test, y_pred_test)\n",
    "precision_test = precision_score(y_test, y_pred_test, average=\"micro\", zero_division=0)\n",
    "recall_test = recall_score(y_test, y_pred_test, average=\"micro\")\n",
    "f1_test = f1_score(y_test, y_pred_test, average=\"macro\")\n",
    "auc_test = roc_auc_score(y_test, y_pred_test, average=\"macro\", multi_class=\"ovr\")\n",
    "\n",
    "print(\"\\nTest:\")\n",
    "print(f\"Accuracy (Test): {accuracy:.2f}\")\n",
    "print(f\"Precision (Test): {precision:.2f}\")\n",
    "print(f\"Recall (Test): {recall:.2f}\")\n",
    "print(f\"F1 (Test): {f1:.2f}\")\n",
    "print(f\"AUC (Test): {auc_test:.2f}\")\n",
    "\n",
    "#Eval Train\n",
    "y_pred_train = best_model.predict(X_train)\n",
    "accuracy_train = accuracy_score(y_train, y_pred_train)\n",
    "precision_train = precision_score(y_train, y_pred_train, average=\"micro\", zero_division=0)\n",
    "recall_train = recall_score(y_train, y_pred_train, average=\"micro\")\n",
    "f1_train = f1_score(y_train, y_pred_train, average=\"macro\")\n",
    "auc_train = roc_auc_score(y_train, y_pred_train, average=\"macro\", multi_class=\"ovr\")\n",
    "\n",
    "print(\"\\nTrain:\")\n",
    "print(f\"Accuracy (Train): {accuracy_train:.2f}\")\n",
    "print(f\"Precision (Train): {precision_train:.2f}\")\n",
    "print(f\"Recall (Train): {recall_train:.2f}\")\n",
    "print(f\"F1 (Train): {f1_train:.2f}\")\n",
    "print(f\"AUC(Train): {auc_train:.2f}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f7cf3262-0835-4b11-a011-5030e7f7797b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Training und Eval des besten Random Forest Modells mit PCA und 200 Features\n",
    "from sklearn.decomposition import PCA\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.metrics import accuracy_score, precision_score, recall_score, f1_score\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "import numpy as np\n",
    "import joblib\n",
    "import os\n",
    "\n",
    "pca = PCA(n_components=200)\n",
    "    \n",
    "scaler = StandardScaler()\n",
    "X_train_scaled = scaler.fit_transform(X_train)\n",
    "X_test_scaled = scaler.transform(X_test)\n",
    "\n",
    "X_train_pca = pca.fit_transform(X_train_scaled)\n",
    "X_test_pca = pca.transform(X_test_scaled)\n",
    "\n",
    "model = RandomForestClassifier(\n",
    "    n_estimators=60,\n",
    "    max_depth=None,\n",
    "    criterion='log_loss',\n",
    "    min_samples_split=2,\n",
    "    min_samples_leaf=7,\n",
    "    max_features='sqrt',\n",
    "    bootstrap=True,\n",
    "    n_jobs=-1,\n",
    "    verbose=2\n",
    ")\n",
    "\n",
    "model.fit(X_train_pca, y_train)\n",
    "\n",
    "#Eval Test\n",
    "y_pred_test = model.predict(X_test_pca)\n",
    "accuracy_test = accuracy_score(y_test, y_pred_test)\n",
    "precision_test = precision_score(y_test, y_pred_test, average=\"micro\", zero_division=0)\n",
    "recall_test = recall_score(y_test, y_pred_test, average=\"micro\")\n",
    "f1_test = f1_score(y_test, y_pred_test, average=\"macro\")\n",
    "auc_test = roc_auc_score(y_test, y_pred_test, average=\"macro\", multi_class=\"ovr\")\n",
    "\n",
    "print(\"Test:\")\n",
    "print(f\"Accuracy (Test): {accuracy_test:.2f}\")\n",
    "print(f\"Precision (Test): {precision_test:.2f}\")\n",
    "print(f\"Recall (Test): {recall_test:.2f}\")\n",
    "print(f\"F1 (Test): {f1_test:.2f}\")\n",
    "print(f\"AUC (Test): {auc_test:.2f}\")\n",
    "\n",
    "#Eval Train\n",
    "y_pred_train = model.predict(X_train_pca)\n",
    "accuracy_train = accuracy_score(y_train, y_pred_train)\n",
    "precision_train = precision_score(y_train, y_pred_train, average=\"micro\", zero_division=0)\n",
    "recall_train = recall_score(y_train, y_pred_train, average=\"micro\")\n",
    "f1_train = f1_score(y_train, y_pred_train, average=\"macro\")\n",
    "auc_train = roc_auc_score(y_train, y_pred_train, average=\"macro\", multi_class=\"ovr\")\n",
    "\n",
    "print(\"Train:\")\n",
    "print(f\"Accuracy (Train): {accuracy_train:.2f}\")\n",
    "print(f\"Precision (Train): {precision_train:.2f}\")\n",
    "print(f\"Recall (Train): {recall_train:.2f}\")\n",
    "print(f\"F1 (Train): {f1_train:.2f}\")\n",
    "print(f\"AUC (Train): {auc_train:.2f}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a1700b97-6d8a-4cb7-9565-c790e2532854",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Plot des Baumgraphen des besten XGBoost Modells ohne PCA\n",
    "from sklearn.datasets import load_iris\n",
    "from sklearn.model_selection import train_test_split\n",
    "import xgboost as xgb\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "model = xgb.XGBClassifier()\n",
    "model.load_model(\"2.model\")\n",
    "\n",
    "xgb.plot_tree(model, num_trees=-1)\n",
    "\n",
    "plt.savefig(\"tree_plot.png\", dpi=300, bbox_inches='tight')\n",
    "\n",
    "plt.show()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
