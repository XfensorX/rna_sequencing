{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import sys\n",
    "import os\n",
    "import pandas as pd\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "from tqdm.notebook import tqdm\n",
    "sys.path.append(\"../../\")\n",
    "from utils.evaluation import evaluate\n",
    "from utils.metrics import Metrics\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import neptune\n",
    "from neptune_pytorch import NeptuneLogger\n",
    "from neptune.utils import stringify_unsupported\n",
    "from dotenv import load_dotenv\n",
    "load_dotenv()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "import pickle\n",
    "from git import Repo\n",
    "\n",
    "# Get the git root directory\n",
    "repo = Repo(\".\", search_parent_directories=True)\n",
    "git_root = repo.git.rev_parse(\"--show-toplevel\")\n",
    "\n",
    "# Load data\n",
    "X_Train_pd = pickle.load(open(f\"{git_root}/data/splits/train/X_pandas.pck\", \"rb\"))\n",
    "y_Train_pd = pickle.load(open(f\"{git_root}/data/splits/train/y_pandas.pck\", \"rb\"))\n",
    "\n",
    "X_Val_pd = pickle.load(open(f\"{git_root}/data/splits/val/X_pandas.pck\", \"rb\"))\n",
    "y_Val_pd = pickle.load(open(f\"{git_root}/data/splits/val/y_pandas.pck\", \"rb\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_Train = torch.tensor(X_Train_pd.values, dtype=torch.float32)\n",
    "y_Train = torch.tensor(y_Train_pd.values, dtype=torch.float32)\n",
    "\n",
    "X_Val = torch.tensor(X_Val_pd.values, dtype=torch.float32)\n",
    "y_Val = torch.tensor(y_Val_pd.values, dtype=torch.float32)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "# class SimpleNetwork(torch.nn.Module):\n",
    "#     def __init__(self):\n",
    "#         super().__init__()\n",
    "\n",
    "#         self.layers = torch.nn.Sequential(\n",
    "#             torch.nn.Linear(5045, 5045),\n",
    "#             torch.nn.LeakyReLU(0.1),\n",
    "#             torch.nn.Linear(5045, 5045),\n",
    "#             torch.nn.LeakyReLU(0.1),\n",
    "#             torch.nn.Linear(5045, 2000),\n",
    "#             torch.nn.LeakyReLU(0.1),\n",
    "#             torch.nn.Linear(2000, 1000),\n",
    "#             torch.nn.LeakyReLU(0.1),\n",
    "#             torch.nn.Linear(1000, 300),\n",
    "#             torch.nn.LeakyReLU(0.1),\n",
    "#             torch.nn.Linear(300, 105),\n",
    "#         )\n",
    "\n",
    "#     def forward(self, x):\n",
    "#         return self.layers(x)\n",
    "\n",
    "class SimpleNetwork(torch.nn.Module):\n",
    "    def __init__(self):\n",
    "        super().__init__()\n",
    "\n",
    "        self.layers = torch.nn.Sequential(\n",
    "            torch.nn.Linear(5045, 3934),\n",
    "            torch.nn.LeakyReLU(0.26250042355767117),\n",
    "            torch.nn.BatchNorm1d(3934),\n",
    "            torch.nn.Dropout(p=0.26081286435916),\n",
    "            torch.nn.Linear(3934, 2246),\n",
    "            torch.nn.LeakyReLU(0.26250042355767117),\n",
    "            torch.nn.BatchNorm1d(2246),\n",
    "            torch.nn.Dropout(p=0.26081286435916),\n",
    "            torch.nn.Linear(2246, 1955),\n",
    "            torch.nn.LeakyReLU(0.26250042355767117),\n",
    "            torch.nn.BatchNorm1d(1955),\n",
    "            torch.nn.Dropout(p=0.26081286435916),\n",
    "            torch.nn.Linear(1955, 745),\n",
    "            torch.nn.LeakyReLU(0.26250042355767117),\n",
    "            torch.nn.BatchNorm1d(745),\n",
    "            torch.nn.Dropout(p=0.26081286435916),\n",
    "            torch.nn.Linear(745, 702),\n",
    "            torch.nn.LeakyReLU(0.26250042355767117),\n",
    "            torch.nn.BatchNorm1d(702),\n",
    "            torch.nn.Dropout(p=0.26081286435916),\n",
    "            torch.nn.Linear(702, 105),\n",
    "        )\n",
    "\n",
    "        # Apply Xavier initialization\n",
    "        for layer in self.layers:\n",
    "            if isinstance(layer, torch.nn.Linear):\n",
    "                torch.nn.init.xavier_normal_(layer.weight)\n",
    "\n",
    "    def forward(self, x):\n",
    "        return self.layers(x)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "class rnaDataset(torch.utils.data.Dataset):\n",
    "    def __init__(self, X, y):\n",
    "        self.X = X\n",
    "        self.y = y\n",
    "\n",
    "    def __len__(self):\n",
    "        return self.X.shape[0]\n",
    "\n",
    "    def __getitem__(self, idx):\n",
    "        return self.X[idx], self.y[idx]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "def label_from_logits(y_hat: torch.Tensor, threshold = 0.5) -> torch.Tensor:\n",
    "    with torch.no_grad():\n",
    "        y_pred_tensor = (torch.sigmoid(y_hat) > threshold).float()\n",
    "    return y_pred_tensor\n",
    "\n",
    "\n",
    "def evaluate_from_dataframe(X: pd.DataFrame):\n",
    "    X_tensor = torch.tensor(X.to_numpy(), dtype=torch.float32)\n",
    "    \n",
    "    #model: a pytorch model, which transforms X -> y in torch.Tensor format\n",
    "    model.eval()\n",
    "    model.cpu()\n",
    "    y_pred_tensor = label_from_logits(model(X_tensor))\n",
    "    \n",
    "    return pd.DataFrame(y_pred_tensor.numpy())\n",
    "\n",
    "def training(model, optimizer, criterion, train_dataloader, val_dataloder, epochs, device, neptune_logger=None, run = None):\n",
    "    criterion = criterion.to(device)\n",
    "    model = model.to(device)\n",
    "    for epoch in tqdm(range(epochs)):\n",
    "        train_acc = 0\n",
    "        val_acc = 0\n",
    "        train_loss = 0\n",
    "        val_loss = 0\n",
    "        model.train()\n",
    "        for x,y in train_dataloader:\n",
    "            x = x.to(device)\n",
    "            y = y.to(device)\n",
    "            y_pred = model(x)\n",
    "            loss = criterion(y_pred, y)\n",
    "            train_loss += loss.item()\n",
    "            loss.backward()\n",
    "            optimizer.step()\n",
    "            optimizer.zero_grad()\n",
    "            train_acc += Metrics.calculate_accuracy(y.cpu().numpy(), label_from_logits(y_pred).cpu().numpy())\n",
    "        \n",
    "        with torch.no_grad():\n",
    "            model.eval()\n",
    "            y_preds = np.array([])\n",
    "            y_trues = np.array([])\n",
    "            for x,y in val_dataloder:\n",
    "                x = x.to(device)\n",
    "                y = y.to(device)\n",
    "                y_pred = model(x)\n",
    "                val_loss += criterion(y_pred, y)\n",
    "                y_pred = label_from_logits(y_pred).cpu().numpy()\n",
    "                y = y.cpu().numpy()\n",
    "                y_preds = np.vstack((y_preds, y_pred)) if y_preds.size else y_pred\n",
    "                y_trues = np.vstack((y_trues, y)) if y_trues.size else y\n",
    "\n",
    "            val_acc = Metrics.calculate_accuracy(y_preds, y_trues)\n",
    "            val_precision = Metrics.calculate_precision(y_preds, y_trues)\n",
    "            val_recall = Metrics.calculate_recall(y_preds, y_trues)\n",
    "            val_f1 = Metrics.calculate_f1_score(y_preds, y_trues)\n",
    "\n",
    "        if neptune_logger:\n",
    "            run[neptune_logger.base_namespace]['train_loss'].append(train_loss)\n",
    "            run[neptune_logger.base_namespace]['train_acc'].append(train_acc/len(train_dataloader))\n",
    "            run[neptune_logger.base_namespace]['val_loss'].append(val_loss)\n",
    "            run[neptune_logger.base_namespace]['val_acc'].append(val_acc)\n",
    "            run[neptune_logger.base_namespace]['val_precision'].append(val_precision)\n",
    "            run[neptune_logger.base_namespace]['val_recall'].append(val_recall)\n",
    "            run[neptune_logger.base_namespace]['val_f1'].append(val_f1)\n",
    "\n",
    "        print(f\"Epoch: {epoch} Train Loss: {train_loss} Train Acc: {train_acc/len(train_dataloader)} Val Loss: {val_loss} Val Acc: {val_acc}\")\n",
    "        #print(f\"CUDA memory allocated: {torch.cuda.memory_allocated(device)/1024**3:.2f} GB\")\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "cuda\n"
     ]
    }
   ],
   "source": [
    "if torch.cuda.is_available():\n",
    "    device = torch.device(\"cuda\")\n",
    "else:\n",
    "    device = torch.device(\"cpu\")\n",
    "print(device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_dataset = torch.utils.data.TensorDataset(X_Train, y_Train)\n",
    "val_dataset = torch.utils.data.TensorDataset(X_Val, y_Val)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "parameters = {\n",
    "    \"batch_size\": 161,\n",
    "    \"lr\": 0.00005667968103081318,\n",
    "    \"epochs\": 35,\n",
    "    \"shuffle\": True,\n",
    "    \"model_name\": \"SimpleNetwork\",\n",
    "    \"optimizer\": \"AdamW\",\n",
    "    \"criterion\": \"BCEWithLogitsLoss\",\n",
    "    \"device\": device,\n",
    "    \"LayerInitialization\": \"Xavier\",\n",
    "    \"drop_out\": True,\n",
    "    \"layerNormaization\": False,\n",
    "    \"batchNormaization\": True,\n",
    "    \"Threshold\": 0.5,\n",
    "    \"weight_decay\": 0.004941861623778181\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_dataloader = torch.utils.data.DataLoader(train_dataset, batch_size=parameters[\"batch_size\"], shuffle=parameters[\"shuffle\"])\n",
    "val_dataloader = torch.utils.data.DataLoader(val_dataset, batch_size=parameters[\"batch_size\"], shuffle=False)\n",
    "\n",
    "model = SimpleNetwork()\n",
    "\n",
    "optimizer = torch.optim.AdamW(model.parameters(), lr=parameters[\"lr\"], weight_decay=parameters[\"weight_decay\"])\n",
    "criterion = torch.nn.BCEWithLogitsLoss()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[neptune] [warning] NeptuneWarning: By default, these monitoring options are disabled in interactive sessions: 'capture_stdout', 'capture_stderr', 'capture_traceback', 'capture_hardware_metrics'. You can set them to 'True' when initializing the run and the monitoring will continue until you call run.stop() or the kernel stops. NOTE: To track the source files, pass their paths to the 'source_code' argument. For help, see: https://docs.neptune.ai/logging/source_code/\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[neptune] [info   ] Neptune initialized. Open in the app: https://app.neptune.ai/JPL/rna-sequencing/e/RNAS-184\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "120152fa69634288bd9903e49e779219",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/35 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 0 Train Loss: 340.4381865262985 Train Acc: 0.0 Val Loss: 34.52456283569336 Val Acc: 0.005701754385964913\n",
      "Epoch: 1 Train Loss: 237.21992021799088 Train Acc: 0.032342770952472205 Val Loss: 20.001052856445312 Val Acc: 0.11019736842105263\n",
      "Epoch: 2 Train Loss: 118.08926412463188 Train Acc: 0.09816212685035709 Val Loss: 9.237150192260742 Val Acc: 0.10657894736842105\n",
      "Epoch: 3 Train Loss: 58.92049115151167 Train Acc: 0.1027320128875148 Val Loss: 5.323086261749268 Val Acc: 0.11896929824561403\n",
      "Epoch: 4 Train Loss: 37.39048132300377 Train Acc: 0.1279598017621147 Val Loss: 3.7923271656036377 Val Acc: 0.1543859649122807\n",
      "Epoch: 5 Train Loss: 28.451277647167444 Train Acc: 0.15798962637152167 Val Loss: 3.056426525115967 Val Acc: 0.1875\n",
      "Epoch: 6 Train Loss: 23.372356072068214 Train Acc: 0.18859490861082992 Val Loss: 2.533606767654419 Val Acc: 0.21611842105263157\n",
      "Epoch: 7 Train Loss: 20.09332551434636 Train Acc: 0.22553492762743904 Val Loss: 2.1967129707336426 Val Acc: 0.25855263157894737\n",
      "Epoch: 8 Train Loss: 17.61534607410431 Train Acc: 0.2728729444277234 Val Loss: 1.9483269453048706 Val Acc: 0.31535087719298244\n",
      "Epoch: 9 Train Loss: 15.736803410574794 Train Acc: 0.3178142186773195 Val Loss: 1.7496224641799927 Val Acc: 0.3530701754385965\n",
      "Epoch: 10 Train Loss: 14.360089210793376 Train Acc: 0.3541095199332364 Val Loss: 1.6546862125396729 Val Acc: 0.38125\n",
      "Epoch: 11 Train Loss: 13.179966328665614 Train Acc: 0.3865356595616602 Val Loss: 1.5564732551574707 Val Acc: 0.40942982456140353\n",
      "Epoch: 12 Train Loss: 12.220345690846443 Train Acc: 0.41601867116316 Val Loss: 1.4809203147888184 Val Acc: 0.4384868421052632\n",
      "Epoch: 13 Train Loss: 11.484158743172884 Train Acc: 0.4404918666374809 Val Loss: 1.4461963176727295 Val Acc: 0.450219298245614\n",
      "Epoch: 14 Train Loss: 10.769032621756196 Train Acc: 0.46199970243795685 Val Loss: 1.4043047428131104 Val Acc: 0.462609649122807\n",
      "Epoch: 15 Train Loss: 10.177604293450713 Train Acc: 0.48215226283963164 Val Loss: 1.370006799697876 Val Acc: 0.4732456140350877\n",
      "Epoch: 16 Train Loss: 9.626214031130075 Train Acc: 0.5021000355706358 Val Loss: 1.3612178564071655 Val Acc: 0.4781798245614035\n",
      "Epoch: 17 Train Loss: 9.166194313205779 Train Acc: 0.5171487228773904 Val Loss: 1.3506710529327393 Val Acc: 0.4820175438596491\n",
      "Epoch: 18 Train Loss: 8.681806824170053 Train Acc: 0.5337711542671083 Val Loss: 1.34871244430542 Val Acc: 0.48793859649122806\n",
      "Epoch: 19 Train Loss: 8.23633236065507 Train Acc: 0.5500404444961281 Val Loss: 1.3580867052078247 Val Acc: 0.4900219298245614\n",
      "Epoch: 20 Train Loss: 7.825791342183948 Train Acc: 0.5663465024489011 Val Loss: 1.3495256900787354 Val Acc: 0.49462719298245617\n",
      "Epoch: 21 Train Loss: 7.441210400313139 Train Acc: 0.5806970305360225 Val Loss: 1.3545819520950317 Val Acc: 0.49736842105263157\n",
      "Epoch: 22 Train Loss: 7.131537489593029 Train Acc: 0.5944733835882556 Val Loss: 1.372523546218872 Val Acc: 0.4969298245614035\n",
      "Epoch: 23 Train Loss: 6.784929550252855 Train Acc: 0.6105374586149344 Val Loss: 1.377913475036621 Val Acc: 0.49835526315789475\n",
      "Epoch: 24 Train Loss: 6.4476204151287675 Train Acc: 0.6194835588420392 Val Loss: 1.3872766494750977 Val Acc: 0.4982456140350877\n",
      "Epoch: 25 Train Loss: 6.141255937516689 Train Acc: 0.6348614455358862 Val Loss: 1.4106806516647339 Val Acc: 0.500109649122807\n",
      "Epoch: 26 Train Loss: 5.8349281353875995 Train Acc: 0.6484608004760996 Val Loss: 1.4163236618041992 Val Acc: 0.49857456140350875\n",
      "Epoch: 27 Train Loss: 5.519057021476328 Train Acc: 0.6613769598051825 Val Loss: 1.4339452981948853 Val Acc: 0.49857456140350875\n",
      "Epoch: 28 Train Loss: 5.252686705440283 Train Acc: 0.6754252230005201 Val Loss: 1.4591989517211914 Val Acc: 0.4944078947368421\n",
      "Epoch: 29 Train Loss: 4.979060923215002 Train Acc: 0.6884794750595128 Val Loss: 1.472819447517395 Val Acc: 0.4982456140350877\n",
      "Epoch: 30 Train Loss: 4.7411687560379505 Train Acc: 0.6988757627165032 Val Loss: 1.4934899806976318 Val Acc: 0.4976973684210526\n",
      "Epoch: 31 Train Loss: 4.470432737376541 Train Acc: 0.7129530980655047 Val Loss: 1.5192571878433228 Val Acc: 0.4888157894736842\n",
      "Epoch: 32 Train Loss: 4.264191374182701 Train Acc: 0.7226396831477273 Val Loss: 1.522611141204834 Val Acc: 0.4953947368421053\n",
      "Epoch: 33 Train Loss: 4.0437336643226445 Train Acc: 0.7326529024270119 Val Loss: 1.5517345666885376 Val Acc: 0.4895833333333333\n",
      "Epoch: 34 Train Loss: 3.8235086197964847 Train Acc: 0.7439824917229868 Val Loss: 1.565107822418213 Val Acc: 0.4941885964912281\n",
      "[neptune] [info   ] Shutting down background jobs, please wait a moment...\n",
      "[neptune] [info   ] Done!\n",
      "[neptune] [info   ] Waiting for the remaining 6 operations to synchronize with Neptune. Do not kill this process.\n",
      "[neptune] [info   ] All 6 operations synced, thanks for waiting!\n",
      "[neptune] [info   ] Explore the metadata in the Neptune app: https://app.neptune.ai/JPL/rna-sequencing/e/RNAS-184/metadata\n"
     ]
    }
   ],
   "source": [
    "run = neptune.init_run(\n",
    "    api_token=os.getenv(\"NEPTUNE_API_KEY\"),\n",
    "    project=os.getenv(\"NEPTUNE_PROJECT_NAME\"),\n",
    "    name=\"SimpleNetwork - best optuna\",\n",
    ")\n",
    "run[\"model/structure\"] = str(model)\n",
    "\n",
    "neptune_logger = NeptuneLogger(run=run, model=model)\n",
    "                               \n",
    "run[neptune_logger.base_namespace][\"hyperparams\"] = stringify_unsupported(parameters)\n",
    "\n",
    "\n",
    "training(model, optimizer, criterion, train_dataloader, val_dataloader, parameters[\"epochs\"], device=device, neptune_logger=neptune_logger, run=run)\n",
    "\n",
    "metrics_test = evaluate(evaluate_from_dataframe)\n",
    "\n",
    "run[\"test\"] = metrics_test.as_dict()\n",
    "\n",
    "neptune_logger.log_model()\n",
    "run.stop()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "torch.save(model.state_dict(), f\"{git_root}/experiments/generating/model.pth\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "# model = SimpleNetwork()\n",
    "# model.load_state_dict(torch.load(f\"{git_root}/experiments/generating/model.pth\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "# metrics_test = evaluate(evaluate_from_dataframe)\n",
    "\n",
    "# for metric, value in metrics_test:\n",
    "#     print(f\"{metric}: {value}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
