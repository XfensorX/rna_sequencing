{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import sys\n",
    "import os\n",
    "import pandas as pd\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "from tqdm.notebook import tqdm\n",
    "sys.path.append(\"../../\")\n",
    "sys.path.append(\"../\")\n",
    "from utils.evaluation import evaluate\n",
    "from utils.metrics import Metrics\n",
    "from models.NNGenerator import AdaptableDenseModel\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import neptune\n",
    "from neptune_pytorch import NeptuneLogger\n",
    "from neptune.utils import stringify_unsupported\n",
    "from dotenv import load_dotenv\n",
    "load_dotenv()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pickle\n",
    "from git import Repo\n",
    "\n",
    "# Get the git root directory\n",
    "repo = Repo(\".\", search_parent_directories=True)\n",
    "git_root = repo.git.rev_parse(\"--show-toplevel\")\n",
    "\n",
    "# Load data\n",
    "X_Train_pd = pickle.load(open(f\"{git_root}/data/splits/train/X_pandas.pck\", \"rb\"))\n",
    "y_Train_pd = pickle.load(open(f\"{git_root}/data/splits/train/y_pandas.pck\", \"rb\"))\n",
    "\n",
    "X_Val_pd = pickle.load(open(f\"{git_root}/data/splits/val/X_pandas.pck\", \"rb\"))\n",
    "y_Val_pd = pickle.load(open(f\"{git_root}/data/splits/val/y_pandas.pck\", \"rb\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_Train = torch.tensor(X_Train_pd.values, dtype=torch.float32)\n",
    "y_Train = torch.tensor(y_Train_pd.values, dtype=torch.float32)\n",
    "\n",
    "X_Val = torch.tensor(X_Val_pd.values, dtype=torch.float32)\n",
    "y_Val = torch.tensor(y_Val_pd.values, dtype=torch.float32)\n",
    "\n",
    "train_dataset = torch.utils.data.TensorDataset(X_Train, y_Train)\n",
    "val_dataset = torch.utils.data.TensorDataset(X_Val, y_Val)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "def label_from_logits(y_hat: torch.Tensor, threshold = 0.5) -> torch.Tensor:\n",
    "    with torch.no_grad():\n",
    "        y_pred_tensor = (torch.sigmoid(y_hat) > threshold).float()\n",
    "    return y_pred_tensor\n",
    "\n",
    "\n",
    "def evaluate_from_dataframe(X: pd.DataFrame):\n",
    "    X_tensor = torch.tensor(X.to_numpy(), dtype=torch.float32)\n",
    "    \n",
    "    #model: a pytorch model, which transforms X -> y in torch.Tensor format\n",
    "    model.eval()\n",
    "    model.cpu()\n",
    "    y_pred_tensor = label_from_logits(model(X_tensor))\n",
    "    \n",
    "    return pd.DataFrame(y_pred_tensor.numpy())\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "from metrics.aats import compute_AAts\n",
    "#from metrics.precision_recall import get_precision_recall\n",
    "\n",
    "def calc_aat(real_data, fake_data):\n",
    "    _, _, aat = compute_AAts(real_data, fake_data)\n",
    "    return aat\n",
    "\n",
    "# def calc_precision_recall(real_data, fake_data):\n",
    "#     precision, recall = get_precision_recall(real_data, fake_data)\n",
    "#     return precision, recall"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "#Adapted from https://forge.ibisc.univ-evry.fr/alacan/GANs-for-transcriptomics/-/blob/master/src/models/utils.py?ref_type=heads\n",
    "def wasserstein_loss(y_true: torch.tensor, y_pred: torch.tensor):\n",
    "    \"\"\"\n",
    "    Returns Wasserstein loss (product of real/fake labels and critic scores on real or fake data)\n",
    "    ----\n",
    "    Parameters:\n",
    "        y_true (torch.tensor): true labels (either real or fake)\n",
    "        y_pred (torch.tensor): critic scores on real or fake data\n",
    "    Returns:\n",
    "        (torch.tensor): mean product of real labels and critic scores\n",
    "    \"\"\"\n",
    "    return torch.mean(y_true * y_pred)\n",
    "\n",
    "\n",
    "def generator_loss(fake_score: torch.tensor):\n",
    "    \"\"\"\n",
    "    Returns generator loss i.e the negative scores of the critic on fake data.\n",
    "    ----\n",
    "    Parameters:\n",
    "        fake_score (torch.tensor): critic scores on fake data\n",
    "    Returns:\n",
    "        (torch.tensor): generator loss\"\"\"\n",
    "\n",
    "    return wasserstein_loss(-torch.ones_like(fake_score), fake_score)\n",
    "\n",
    "\n",
    "def discriminator_loss(real_score: torch.tensor, fake_score: torch.tensor):\n",
    "    \"\"\"\n",
    "    Compute and return the wasserstein loss of critic scores on real and fake data i.e: wassertstein_loss = mean(-score_real) + mean(score_fake)\n",
    "    ----\n",
    "    Parameters:\n",
    "        real_score (torch.tensor): critic scores on real data\n",
    "        fake_score (torch.tensor): critic scores on fake data\n",
    "    Returns:\n",
    "        (torch.tensor): wasserstein loss\n",
    "    \"\"\"\n",
    "    real_loss = wasserstein_loss(-torch.ones_like(real_score), real_score)\n",
    "    fake_loss = wasserstein_loss(torch.ones_like(fake_score), fake_score)\n",
    "\n",
    "    return real_loss, fake_loss\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "def training(D, G, d_optimizer, g_optimizer, train_loader, val_loader, epochs, latentSpaceSize, lambda_gp, iters_critic, device, neptune_logger=None, run = None, trial = None):\n",
    "# Code adopted from https://pytorch.org/tutorials/beginner/dcgan_faces_tutorial.html\n",
    "# and https://github.com/Zeleni9/pytorch-wgan/blob/master/models/wgan_gradient_penalty.py\n",
    "    one = torch.tensor(1, dtype=torch.float).to(device)\n",
    "    mone = (one * -1).to(device)\n",
    "    D = D.to(device)\n",
    "    G = G.to(device)\n",
    "    aat = 0\n",
    "\n",
    "    print(\"Starting Training Loop...\")\n",
    "    # For each epoch\n",
    "    for epoch in tqdm(range(epochs)):\n",
    "        errDItem = 0\n",
    "        errGItem = 0\n",
    "        Wasserstein_D = 0\n",
    "        G.train()\n",
    "        D.train()\n",
    "\n",
    "        # For each batch in the dataloader\n",
    "        for X,y in train_loader:\n",
    "\n",
    "            y = y.to(device).long()\n",
    "            \n",
    "            ############################\n",
    "            # (1) Update D network: maximize D(x|c) - D(G(z|c)) + lambda_gp * gradient_penalty\n",
    "            ###########################\n",
    "            ## Train with all-real batch\n",
    "            for p in D.parameters():\n",
    "                p.requires_grad = True  \n",
    "\n",
    "            for p in G.parameters():\n",
    "                p.requires_grad = False  # to avoid computation\n",
    "\n",
    "            d_optimizer.zero_grad()\n",
    "            b_size = X.size(0)\n",
    "\n",
    "            real_data = X.to(device)\n",
    "\n",
    "            for crit_step in range(iters_critic):\n",
    "                # Forward pass real batch through D\n",
    "                \n",
    "                errD_real = D(real_data, y)\n",
    "                # Calculate loss on all-real batch\n",
    "                errD_real = errD_real.mean()\n",
    "                # Calculate gradients for D in backward pass\n",
    "                errD_real.backward(mone)\n",
    "\n",
    "                ## Train with all-fake batch\n",
    "                # Generate batch of latent vectors\n",
    "                z = torch.randn(b_size, latentSpaceSize)\n",
    "                # Generate fake image batch with G\n",
    "                fake_data = G(z.to(device), y)\n",
    "                # Classify all fake batch with D\n",
    "                #print(fake.shape)\n",
    "                errD_fake = D(fake_data.detach(), y)\n",
    "                # Calculate D's loss on the all-fake batch\n",
    "                errD_fake = errD_fake.mean()\n",
    "                # Calculate the gradients for this batch, accumulated (summed) with previous gradients\n",
    "                errD_fake.backward(one)\n",
    "                \n",
    "                # Gradient penalty\n",
    "                alpha = torch.rand(real_data.size(0), 1, device=device, requires_grad=True)\n",
    "                alpha = alpha.expand(real_data.size())\n",
    "                interpolates = alpha * real_data + ((1 - alpha) * fake_data.detach())\n",
    "                interpolates.requires_grad_(True)\n",
    "\n",
    "                d_interpolates = D(interpolates, y)\n",
    "                gradients = torch.autograd.grad(\n",
    "                    outputs=d_interpolates,\n",
    "                    inputs=interpolates,\n",
    "                    grad_outputs=torch.ones(d_interpolates.size(), device=device),\n",
    "                    create_graph=True,\n",
    "                    retain_graph=True,\n",
    "                    only_inputs=True,\n",
    "                )[0]\n",
    "\n",
    "                gradients = gradients.view(gradients.size(0), -1)\n",
    "                gradient_penalty = ((gradients.norm(2, dim=1) - 1) ** 2).mean() * lambda_gp\n",
    "                gradient_penalty.backward()\n",
    "\n",
    "                # Compute error of D as sum of the errors on the real and fake batches and the gradient penalty\n",
    "                errD = errD_real - errD_fake + gradient_penalty\n",
    "                errDItem += errD.item()\n",
    "                Wasserstein_D += errD_real.item() - errD_fake.item()\n",
    "                # Update D\n",
    "                d_optimizer.step()\n",
    "\n",
    "            Wasserstein_D /= iters_critic\n",
    "            errDItem /= iters_critic\n",
    "            ############################\n",
    "            # (2) Update G network: maximize D(G(z|c))\n",
    "            ###########################\n",
    "            for p in D.parameters():\n",
    "                p.requires_grad = False  # to avoid computation\n",
    "\n",
    "            for p in G.parameters():\n",
    "                p.requires_grad = True\n",
    "\n",
    "            g_optimizer.zero_grad()\n",
    "\n",
    "            z = torch.randn(b_size, latentSpaceSize)\n",
    "            # Generate fake image batch with G\n",
    "            fake_data = G(z.to(device), y)\n",
    "            # Calculate G's loss based on this output\n",
    "            errG = D(fake_data, y)\n",
    "            errG = errG.mean()\n",
    "            # Calculate gradients for G\n",
    "            errG.backward(mone)\n",
    "            errGItem += errG.item()\n",
    "            # Update G\n",
    "            g_optimizer.step()\n",
    "\n",
    "        with torch.no_grad():\n",
    "            G.eval()\n",
    "            real_datas = np.array([])\n",
    "            fake_datas = np.array([])\n",
    "            for X_val, y_val in val_loader:\n",
    "                y_val = y_val.to(device).long()\n",
    "                X_val = X_val.to(device).to(torch.float16)\n",
    "                z = torch.randn(X_val.size(0), latentSpaceSize)\n",
    "                fake_data = G(z.to(device), y_val).to(torch.float16)\n",
    "                real_datas = torch.vstack((real_datas, X_val)) if real_datas.size else real_data\n",
    "                fake_datas = torch.vstack((fake_datas, fake_data)) if fake_datas.size else fake_data\n",
    "            aat = calc_aat(real_datas.cpu(), fake_datas.cpu())\n",
    "            #with torch.device(device):\n",
    "            #    recall, precision = calc_precision_recall(real_datas, fake_datas)\n",
    "\n",
    "        errDItem /= len(train_loader)\n",
    "        errGItem /= len(train_loader)\n",
    "        Wasserstein_D /= len(train_loader)\n",
    "        if neptune_logger is not None:\n",
    "            run[neptune_logger.base_namespace]['D_Loss'].append(errDItem)\n",
    "            run[neptune_logger.base_namespace]['G_Loss'].append(errGItem)\n",
    "            run[neptune_logger.base_namespace]['Wasserstein_D'].append(Wasserstein_D)\n",
    "            run[neptune_logger.base_namespace]['AAT'].append(aat)\n",
    "            #run[neptune_logger.base_namespace]['Precision'].append(precision)\n",
    "            #run[neptune_logger.base_namespace]['Recall'].append(recall)\n",
    "\n",
    "        print(f\"Epoch {epoch} D Loss: {errDItem} G Loss: {errGItem} Wasserstein D: {Wasserstein_D}\")\n",
    "            "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Discriminator(nn.Module):\n",
    "    def __init__(self, input_size, output_size, class_size, embedding_size):\n",
    "        super().__init__()\n",
    "        self.model = nn.Sequential(\n",
    "            nn.Linear(input_size + embedding_size * class_size, 3000),\n",
    "            nn.ReLU(),\n",
    "            nn.BatchNorm1d(3000),\n",
    "            nn.Dropout(0.4),\n",
    "            nn.Linear(3000, 1000),\n",
    "            nn.ReLU(),\n",
    "            nn.BatchNorm1d(1000),\n",
    "            nn.Dropout(0.4),\n",
    "            nn.Linear(1000, 128),\n",
    "            nn.ReLU(),\n",
    "            nn.BatchNorm1d(128),\n",
    "            nn.Dropout(0.4),\n",
    "            nn.Linear(128, output_size),\n",
    "            nn.Sigmoid()\n",
    "        )\n",
    "        self.embedding = nn.Embedding(class_size, embedding_size)\n",
    "\n",
    "        for m in self.modules():\n",
    "            if isinstance(m, nn.Linear):\n",
    "                nn.init.xavier_normal_(m.weight)\n",
    "\n",
    "    def forward(self, x, cls):\n",
    "        cls = self.embedding(cls)\n",
    "        x = torch.cat((x, cls.flatten(start_dim=1)), 1)\n",
    "        return self.model(x)\n",
    "    \n",
    "class Generator(nn.Module):\n",
    "    def __init__(self, input_size, output_size, class_size, embedding_size):\n",
    "        super().__init__()\n",
    "        self.model = nn.Sequential(\n",
    "            nn.Linear(input_size + embedding_size * class_size, 512),\n",
    "            nn.ReLU(),\n",
    "            nn.Linear(512, 1024),\n",
    "            nn.ReLU(),\n",
    "            nn.Linear(1024, 2048),\n",
    "            nn.ReLU(),\n",
    "            nn.Linear(2048, 4096),\n",
    "            nn.ReLU(),\n",
    "            nn.Linear(4096, output_size)\n",
    "        )\n",
    "        self.embedding = nn.Embedding(class_size, embedding_size)\n",
    "\n",
    "        for m in self.modules():\n",
    "            if isinstance(m, nn.Linear):\n",
    "                nn.init.xavier_normal_(m.weight)\n",
    "\n",
    "    def forward(self, x, cls):\n",
    "        cls = self.embedding(cls)\n",
    "        x = torch.cat((x, cls.flatten(start_dim=1)), 1)\n",
    "        return self.model(x)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "input_dim_data = X_Train.shape[1]\n",
    "output_dim_data = y_Train.shape[1]\n",
    "latentSpaceSize = 256\n",
    "\n",
    "# Define the generator\n",
    "\n",
    "G = Generator(latentSpaceSize, input_dim_data, output_dim_data, 2)\n",
    "\n",
    "# Define the discriminator\n",
    "D = Discriminator(input_dim_data, 1, output_dim_data, 2)\n",
    "\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "params = {\n",
    "    \"epochs\": 20,\n",
    "    \"lambda_gp\": 10,\n",
    "    \"latentSpaceSize\": latentSpaceSize,\n",
    "    \"device\": device,\n",
    "    \"batch_size\": 64,\n",
    "    \"lr\": 0.0001,\n",
    "    \"critic_iter\": 5,\n",
    "    \"b1\": 0.5,\n",
    "    \"b2\": 0.999\n",
    "}\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "train_loader = torch.utils.data.DataLoader(train_dataset, batch_size=params[\"batch_size\"], shuffle=True)\n",
    "val_loader = torch.utils.data.DataLoader(val_dataset, batch_size=1024, shuffle=True)\n",
    "\n",
    "d_optimizer = torch.optim.Adam(D.parameters(), lr=params[\"lr\"], betas=(params[\"b1\"], params[\"b2\"]))\n",
    "g_optimizer = torch.optim.Adam(G.parameters(), lr=params[\"lr\"], betas=(params[\"b1\"], params[\"b2\"]))\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[neptune] [warning] NeptuneWarning: By default, these monitoring options are disabled in interactive sessions: 'capture_stdout', 'capture_stderr', 'capture_traceback', 'capture_hardware_metrics'. You can set them to 'True' when initializing the run and the monitoring will continue until you call run.stop() or the kernel stops. NOTE: To track the source files, pass their paths to the 'source_code' argument. For help, see: https://docs.neptune.ai/logging/source_code/\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[neptune] [info   ] Neptune initialized. Open in the app: https://app.neptune.ai/JPL/rna-sequencing/e/RNAS-171\n",
      "Starting Training Loop...\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "3260a131035b443cb37fcd0634c82656",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/20 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 4/4 [00:17<00:00,  4.31s/it]\n",
      "c:\\Users\\Julius\\Documents\\LuH\\rna_sequencing\\.venv\\lib\\site-packages\\numpy\\_core\\fromnumeric.py:3596: RuntimeWarning: Mean of empty slice.\n",
      "  return _methods._mean(a, axis=axis, dtype=dtype,\n",
      "c:\\Users\\Julius\\Documents\\LuH\\rna_sequencing\\.venv\\lib\\site-packages\\numpy\\_core\\_methods.py:138: RuntimeWarning: invalid value encountered in scalar divide\n",
      "  ret = ret.dtype.type(ret / rcount)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 0 D Loss: 0.016260985444895043 G Loss: 0.49264545841868984 Wasserstein D: 7.4185301643845385e-06\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 4/4 [00:17<00:00,  4.44s/it]\n",
      "c:\\Users\\Julius\\Documents\\LuH\\rna_sequencing\\.venv\\lib\\site-packages\\numpy\\_core\\fromnumeric.py:3596: RuntimeWarning: Mean of empty slice.\n",
      "  return _methods._mean(a, axis=axis, dtype=dtype,\n",
      "c:\\Users\\Julius\\Documents\\LuH\\rna_sequencing\\.venv\\lib\\site-packages\\numpy\\_core\\_methods.py:138: RuntimeWarning: invalid value encountered in scalar divide\n",
      "  ret = ret.dtype.type(ret / rcount)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1 D Loss: 0.009524042271045054 G Loss: 0.4778437015521328 Wasserstein D: 0.0003423478946925875\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 4/4 [00:17<00:00,  4.26s/it]\n",
      "c:\\Users\\Julius\\Documents\\LuH\\rna_sequencing\\.venv\\lib\\site-packages\\numpy\\_core\\fromnumeric.py:3596: RuntimeWarning: Mean of empty slice.\n",
      "  return _methods._mean(a, axis=axis, dtype=dtype,\n",
      "c:\\Users\\Julius\\Documents\\LuH\\rna_sequencing\\.venv\\lib\\site-packages\\numpy\\_core\\_methods.py:138: RuntimeWarning: invalid value encountered in scalar divide\n",
      "  ret = ret.dtype.type(ret / rcount)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 2 D Loss: 0.009743568447708408 G Loss: 0.4442377671351253 Wasserstein D: 0.00011703987946582822\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 4/4 [00:17<00:00,  4.41s/it]\n",
      "c:\\Users\\Julius\\Documents\\LuH\\rna_sequencing\\.venv\\lib\\site-packages\\numpy\\_core\\fromnumeric.py:3596: RuntimeWarning: Mean of empty slice.\n",
      "  return _methods._mean(a, axis=axis, dtype=dtype,\n",
      "c:\\Users\\Julius\\Documents\\LuH\\rna_sequencing\\.venv\\lib\\site-packages\\numpy\\_core\\_methods.py:138: RuntimeWarning: invalid value encountered in scalar divide\n",
      "  ret = ret.dtype.type(ret / rcount)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 3 D Loss: 0.011068590348177082 G Loss: 0.3294036224758698 Wasserstein D: 0.00039415535688908576\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 4/4 [00:17<00:00,  4.48s/it]\n",
      "c:\\Users\\Julius\\Documents\\LuH\\rna_sequencing\\.venv\\lib\\site-packages\\numpy\\_core\\fromnumeric.py:3596: RuntimeWarning: Mean of empty slice.\n",
      "  return _methods._mean(a, axis=axis, dtype=dtype,\n",
      "c:\\Users\\Julius\\Documents\\LuH\\rna_sequencing\\.venv\\lib\\site-packages\\numpy\\_core\\_methods.py:138: RuntimeWarning: invalid value encountered in scalar divide\n",
      "  ret = ret.dtype.type(ret / rcount)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 4 D Loss: 0.01122750897506513 G Loss: 0.3036306252561046 Wasserstein D: 0.0004635800357487995\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 4/4 [00:17<00:00,  4.43s/it]\n",
      "c:\\Users\\Julius\\Documents\\LuH\\rna_sequencing\\.venv\\lib\\site-packages\\numpy\\_core\\fromnumeric.py:3596: RuntimeWarning: Mean of empty slice.\n",
      "  return _methods._mean(a, axis=axis, dtype=dtype,\n",
      "c:\\Users\\Julius\\Documents\\LuH\\rna_sequencing\\.venv\\lib\\site-packages\\numpy\\_core\\_methods.py:138: RuntimeWarning: invalid value encountered in scalar divide\n",
      "  ret = ret.dtype.type(ret / rcount)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 5 D Loss: 0.01089974301769699 G Loss: 0.28204929740490564 Wasserstein D: 0.0001774547632853972\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 4/4 [00:17<00:00,  4.48s/it]\n",
      "c:\\Users\\Julius\\Documents\\LuH\\rna_sequencing\\.venv\\lib\\site-packages\\numpy\\_core\\fromnumeric.py:3596: RuntimeWarning: Mean of empty slice.\n",
      "  return _methods._mean(a, axis=axis, dtype=dtype,\n",
      "c:\\Users\\Julius\\Documents\\LuH\\rna_sequencing\\.venv\\lib\\site-packages\\numpy\\_core\\_methods.py:138: RuntimeWarning: invalid value encountered in scalar divide\n",
      "  ret = ret.dtype.type(ret / rcount)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 6 D Loss: 0.011323772300848904 G Loss: 0.4786574091177881 Wasserstein D: 0.00043236208285085366\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 4/4 [00:17<00:00,  4.33s/it]\n",
      "c:\\Users\\Julius\\Documents\\LuH\\rna_sequencing\\.venv\\lib\\site-packages\\numpy\\_core\\fromnumeric.py:3596: RuntimeWarning: Mean of empty slice.\n",
      "  return _methods._mean(a, axis=axis, dtype=dtype,\n",
      "c:\\Users\\Julius\\Documents\\LuH\\rna_sequencing\\.venv\\lib\\site-packages\\numpy\\_core\\_methods.py:138: RuntimeWarning: invalid value encountered in scalar divide\n",
      "  ret = ret.dtype.type(ret / rcount)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 7 D Loss: 0.011311288658963713 G Loss: 0.26760345080983317 Wasserstein D: 0.00036800679893960424\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 50%|█████     | 2/4 [00:17<00:17,  8.60s/it]\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[11], line 15\u001b[0m\n\u001b[0;32m     10\u001b[0m run[neptune_logger\u001b[38;5;241m.\u001b[39mbase_namespace][\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mG_Structure\u001b[39m\u001b[38;5;124m\"\u001b[39m] \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mstr\u001b[39m(G)\n\u001b[0;32m     11\u001b[0m run[neptune_logger\u001b[38;5;241m.\u001b[39mbase_namespace][\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mD_Structure\u001b[39m\u001b[38;5;124m\"\u001b[39m] \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mstr\u001b[39m(D)\n\u001b[1;32m---> 15\u001b[0m \u001b[43mtraining\u001b[49m\u001b[43m(\u001b[49m\u001b[43mD\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mG\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43md_optimizer\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mg_optimizer\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mtrain_loader\u001b[49m\u001b[43m \u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mval_loader\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mparams\u001b[49m\u001b[43m[\u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mepochs\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m]\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mlatentSpaceSize\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mparams\u001b[49m\u001b[43m[\u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mlambda_gp\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m]\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mparams\u001b[49m\u001b[43m[\u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mcritic_iter\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m]\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mdevice\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mneptune_logger\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mneptune_logger\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mrun\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mrun\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m     17\u001b[0m neptune_logger\u001b[38;5;241m.\u001b[39mlog_model()\n\u001b[0;32m     18\u001b[0m run\u001b[38;5;241m.\u001b[39mstop()\n",
      "Cell \u001b[1;32mIn[7], line 124\u001b[0m, in \u001b[0;36mtraining\u001b[1;34m(D, G, d_optimizer, g_optimizer, train_loader, val_loader, epochs, latentSpaceSize, lambda_gp, iters_critic, device, neptune_logger, run, trial)\u001b[0m\n\u001b[0;32m    122\u001b[0m         real_datas \u001b[38;5;241m=\u001b[39m torch\u001b[38;5;241m.\u001b[39mvstack((real_datas, X_val)) \u001b[38;5;28;01mif\u001b[39;00m real_datas\u001b[38;5;241m.\u001b[39msize \u001b[38;5;28;01melse\u001b[39;00m real_data\n\u001b[0;32m    123\u001b[0m         fake_datas \u001b[38;5;241m=\u001b[39m torch\u001b[38;5;241m.\u001b[39mvstack((fake_datas, fake_data)) \u001b[38;5;28;01mif\u001b[39;00m fake_datas\u001b[38;5;241m.\u001b[39msize \u001b[38;5;28;01melse\u001b[39;00m fake_data\n\u001b[1;32m--> 124\u001b[0m     aat \u001b[38;5;241m=\u001b[39m \u001b[43mcalc_aat\u001b[49m\u001b[43m(\u001b[49m\u001b[43mreal_datas\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mcpu\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mfake_datas\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mcpu\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    125\u001b[0m     \u001b[38;5;66;03m#with torch.device(device):\u001b[39;00m\n\u001b[0;32m    126\u001b[0m     \u001b[38;5;66;03m#    recall, precision = calc_precision_recall(real_datas, fake_datas)\u001b[39;00m\n\u001b[0;32m    128\u001b[0m errDItem \u001b[38;5;241m/\u001b[39m\u001b[38;5;241m=\u001b[39m \u001b[38;5;28mlen\u001b[39m(train_loader)\n",
      "Cell \u001b[1;32mIn[6], line 5\u001b[0m, in \u001b[0;36mcalc_aat\u001b[1;34m(real_data, fake_data)\u001b[0m\n\u001b[0;32m      4\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mcalc_aat\u001b[39m(real_data, fake_data):\n\u001b[1;32m----> 5\u001b[0m     _, _, aat \u001b[38;5;241m=\u001b[39m \u001b[43mcompute_AAts\u001b[49m\u001b[43m(\u001b[49m\u001b[43mreal_data\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mfake_data\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m      6\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m aat\n",
      "File \u001b[1;32mc:\\Users\\Julius\\Documents\\LuH\\rna_sequencing\\experiments\\generating\\metrics\\aats.py:139\u001b[0m, in \u001b[0;36mcompute_AAts\u001b[1;34m(real_data, fake_data)\u001b[0m\n\u001b[0;32m    130\u001b[0m \u001b[38;5;250m\u001b[39m\u001b[38;5;124;03m\"\"\" Compute similarity scores based on nearest neighbors distances.\u001b[39;00m\n\u001b[0;32m    131\u001b[0m \u001b[38;5;124;03m----\u001b[39;00m\n\u001b[0;32m    132\u001b[0m \u001b[38;5;124;03mParameters:\u001b[39;00m\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m    136\u001b[0m \u001b[38;5;124;03m    discrepancy score, divergence score, adversarial accuracy\u001b[39;00m\n\u001b[0;32m    137\u001b[0m \u001b[38;5;124;03m\"\"\"\u001b[39;00m\n\u001b[0;32m    138\u001b[0m nnm \u001b[38;5;241m=\u001b[39m NearestNeighborMetrics(real_data, fake_data)\n\u001b[1;32m--> 139\u001b[0m \u001b[43mnnm\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mcompute_nn\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    141\u001b[0m \u001b[38;5;66;03m# run discrepancy score, divergence, adversarial accuracy\u001b[39;00m\n\u001b[0;32m    142\u001b[0m discrepancy \u001b[38;5;241m=\u001b[39m nnm\u001b[38;5;241m.\u001b[39mcompute_discrepancy()\n",
      "File \u001b[1;32mc:\\Users\\Julius\\Documents\\LuH\\rna_sequencing\\experiments\\generating\\metrics\\aats.py:66\u001b[0m, in \u001b[0;36mNearestNeighborMetrics.compute_nn\u001b[1;34m(self)\u001b[0m\n\u001b[0;32m     61\u001b[0m futures \u001b[38;5;241m=\u001b[39m [\n\u001b[0;32m     62\u001b[0m     executor\u001b[38;5;241m.\u001b[39msubmit(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mnearest_neighbors, t, s)\n\u001b[0;32m     63\u001b[0m     \u001b[38;5;28;01mfor\u001b[39;00m (t, s) \u001b[38;5;129;01min\u001b[39;00m tasks\n\u001b[0;32m     64\u001b[0m ]\n\u001b[0;32m     65\u001b[0m \u001b[38;5;66;03m# wait for each job to finish\u001b[39;00m\n\u001b[1;32m---> 66\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m future \u001b[38;5;129;01min\u001b[39;00m tqdm(\n\u001b[0;32m     67\u001b[0m         concurrent\u001b[38;5;241m.\u001b[39mfutures\u001b[38;5;241m.\u001b[39mas_completed(futures),\n\u001b[0;32m     68\u001b[0m         total\u001b[38;5;241m=\u001b[39m\u001b[38;5;28mlen\u001b[39m(futures)):\n\u001b[0;32m     69\u001b[0m     t, s, d \u001b[38;5;241m=\u001b[39m future\u001b[38;5;241m.\u001b[39mresult()\n\u001b[0;32m     70\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mdists[(t, s)] \u001b[38;5;241m=\u001b[39m d\n",
      "File \u001b[1;32mc:\\Users\\Julius\\Documents\\LuH\\rna_sequencing\\.venv\\lib\\site-packages\\tqdm\\std.py:1181\u001b[0m, in \u001b[0;36mtqdm.__iter__\u001b[1;34m(self)\u001b[0m\n\u001b[0;32m   1178\u001b[0m time \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_time\n\u001b[0;32m   1180\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[1;32m-> 1181\u001b[0m     \u001b[38;5;28;01mfor\u001b[39;00m obj \u001b[38;5;129;01min\u001b[39;00m iterable:\n\u001b[0;32m   1182\u001b[0m         \u001b[38;5;28;01myield\u001b[39;00m obj\n\u001b[0;32m   1183\u001b[0m         \u001b[38;5;66;03m# Update and possibly print the progressbar.\u001b[39;00m\n\u001b[0;32m   1184\u001b[0m         \u001b[38;5;66;03m# Note: does not call self.update(1) for speed optimisation.\u001b[39;00m\n",
      "File \u001b[1;32m~\\AppData\\Local\\Programs\\Python\\Python310\\lib\\concurrent\\futures\\_base.py:245\u001b[0m, in \u001b[0;36mas_completed\u001b[1;34m(fs, timeout)\u001b[0m\n\u001b[0;32m    240\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m wait_timeout \u001b[38;5;241m<\u001b[39m \u001b[38;5;241m0\u001b[39m:\n\u001b[0;32m    241\u001b[0m         \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mTimeoutError\u001b[39;00m(\n\u001b[0;32m    242\u001b[0m                 \u001b[38;5;124m'\u001b[39m\u001b[38;5;132;01m%d\u001b[39;00m\u001b[38;5;124m (of \u001b[39m\u001b[38;5;132;01m%d\u001b[39;00m\u001b[38;5;124m) futures unfinished\u001b[39m\u001b[38;5;124m'\u001b[39m \u001b[38;5;241m%\u001b[39m (\n\u001b[0;32m    243\u001b[0m                 \u001b[38;5;28mlen\u001b[39m(pending), total_futures))\n\u001b[1;32m--> 245\u001b[0m \u001b[43mwaiter\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mevent\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mwait\u001b[49m\u001b[43m(\u001b[49m\u001b[43mwait_timeout\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    247\u001b[0m \u001b[38;5;28;01mwith\u001b[39;00m waiter\u001b[38;5;241m.\u001b[39mlock:\n\u001b[0;32m    248\u001b[0m     finished \u001b[38;5;241m=\u001b[39m waiter\u001b[38;5;241m.\u001b[39mfinished_futures\n",
      "File \u001b[1;32m~\\AppData\\Local\\Programs\\Python\\Python310\\lib\\threading.py:607\u001b[0m, in \u001b[0;36mEvent.wait\u001b[1;34m(self, timeout)\u001b[0m\n\u001b[0;32m    605\u001b[0m signaled \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_flag\n\u001b[0;32m    606\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m signaled:\n\u001b[1;32m--> 607\u001b[0m     signaled \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_cond\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mwait\u001b[49m\u001b[43m(\u001b[49m\u001b[43mtimeout\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    608\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m signaled\n",
      "File \u001b[1;32m~\\AppData\\Local\\Programs\\Python\\Python310\\lib\\threading.py:320\u001b[0m, in \u001b[0;36mCondition.wait\u001b[1;34m(self, timeout)\u001b[0m\n\u001b[0;32m    318\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:    \u001b[38;5;66;03m# restore state no matter what (e.g., KeyboardInterrupt)\u001b[39;00m\n\u001b[0;32m    319\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m timeout \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[1;32m--> 320\u001b[0m         \u001b[43mwaiter\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43macquire\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    321\u001b[0m         gotit \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mTrue\u001b[39;00m\n\u001b[0;32m    322\u001b[0m     \u001b[38;5;28;01melse\u001b[39;00m:\n",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "run = neptune.init_run(\n",
    "    api_token=os.getenv(\"NEPTUNE_API_KEY\"),\n",
    "    project=os.getenv(\"NEPTUNE_PROJECT_NAME\"),\n",
    "    name=\"WGAN-GP\",\n",
    ")\n",
    "\n",
    "neptune_logger = NeptuneLogger(run=run, model=G)\n",
    "                               \n",
    "run[neptune_logger.base_namespace][\"hyperparams\"] = stringify_unsupported(params)\n",
    "run[neptune_logger.base_namespace][\"G_Structure\"] = str(G)\n",
    "run[neptune_logger.base_namespace][\"D_Structure\"] = str(D)\n",
    "\n",
    "\n",
    "\n",
    "training(D, G, d_optimizer, g_optimizer, train_loader , val_loader, params[\"epochs\"], latentSpaceSize, params[\"lambda_gp\"], params[\"critic_iter\"], device, neptune_logger=neptune_logger, run=run)\n",
    "\n",
    "neptune_logger.log_model()\n",
    "run.stop()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Generator(\n",
       "  (model): Sequential(\n",
       "    (0): Linear(in_features=653, out_features=256, bias=True)\n",
       "    (1): ReLU()\n",
       "    (2): BatchNorm1d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "    (3): Linear(in_features=256, out_features=1024, bias=True)\n",
       "    (4): ReLU()\n",
       "    (5): BatchNorm1d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "    (6): Linear(in_features=1024, out_features=2048, bias=True)\n",
       "    (7): ReLU()\n",
       "    (8): BatchNorm1d(2048, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "    (9): Linear(in_features=2048, out_features=4096, bias=True)\n",
       "    (10): ReLU()\n",
       "    (11): BatchNorm1d(4096, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "    (12): Linear(in_features=4096, out_features=5045, bias=True)\n",
       "  )\n",
       "  (embedding): Embedding(105, 5)\n",
       ")"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "G.eval()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[-26.4828,  17.0079,   0.3647,  ...,  -7.2669,  -2.4989,  13.0806]],\n",
       "       device='cuda:0', grad_fn=<AddmmBackward0>)"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "G(torch.randn(1, latentSpaceSize, device=device), y_Val[0].long().unsqueeze(dim=0).to(device))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([0.0000, 0.0000, 0.0000,  ..., 3.3789, 0.0000, 0.0000])"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_Val[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
